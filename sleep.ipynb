{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv81IKEvI6fR2806Q5qGPb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saurabh1826/sleep-staging/blob/master/sleep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNZb8Vaf4Ac3",
        "outputId": "d5cbba58-17ff-4110-d9a5-11481d416511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# !wget -r -N -c -np https://physionet.org/files/sleep-accel/1.0.0/\n",
        "\n",
        "file = 'gdrive/MyDrive/Sleep Files/1.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ojwalch/sleep_classifiers.git\n",
        "# !cp -r 'gdrive/MyDrive/Sleep Files/1.0.0/heart_rate/' 'sleep_classifiers/data'\n",
        "# !cp -r 'gdrive/MyDrive/Sleep Files/1.0.0/labels/' 'sleep_classifiers/data'\n",
        "# !cp -r 'gdrive/MyDrive/Sleep Files/1.0.0/motion/' 'sleep_classifiers/data'\n",
        "# !pip install -r sleep_classifiers/requirements.txt\n",
        "# !pip install docx2txt"
      ],
      "metadata": {
        "id": "C4EqND9FZM5m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python sleep_classifiers/source/preprocessing/preprocessing_runner.py"
      ],
      "metadata": {
        "id": "LBbc3dlRb0Fr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r 'gdrive/MyDrive/Sleep Files/1.0.0/features' '.'"
      ],
      "metadata": {
        "id": "vBmtHq9GrWP7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature matrix of the features\n",
        "\n",
        "# Variable with name of the directory containing all the features\n",
        "dirName = 'features'\n",
        "# List that will be the feature matrix. It will be an array of feature matrices,\n",
        "# where each feature matrix is for a single subject\n",
        "features = []\n",
        "# List that will be the labels vector. It will be an array of arrays, where each\n",
        "# array is the label array for a single subject\n",
        "labels = []\n",
        "# Dict that maps the number of a file to all the files with that number\n",
        "fileDict = {}\n",
        "\n",
        "# Iterate over the directory dirName and put files in fileDict\n",
        "dir = os.fsencode(dirName)\n",
        "for file in os.listdir(dir) :\n",
        "  fileName = os.fsdecode(file)\n",
        "  if (not fileName.endswith('.out')) : continue\n",
        "  fileNum = fileName.split('_')[0]\n",
        "  if (fileNum in fileDict) :\n",
        "    fileDict[fileNum].append(fileName)\n",
        "  else :\n",
        "    fileDict[fileNum] = [fileName]\n",
        "\n",
        "# Iterate through fileDict and create the feature matrix\n",
        "for subj, files in fileDict.items() :\n",
        "  for fileName in files :\n",
        "    if (fileName.split('_')[1] == 'cosine') :\n",
        "      cosFile = open(os.path.join('.', 'features', fileName), 'r')\n",
        "    elif (fileName.split('_')[1] == 'count') :\n",
        "      cntFile = open(os.path.join('.', 'features', fileName), 'r')\n",
        "    elif (fileName.split('_')[1] == 'hr') :\n",
        "      hrFile = open(os.path.join('.', 'features', fileName), 'r')\n",
        "    elif (fileName.split('_')[1] == 'psg') :\n",
        "      labelsFile = open(os.path.join('.', 'features', fileName), 'r')\n",
        "    else :\n",
        "      timeFile = open(os.path.join('.', 'features', fileName), 'r')\n",
        "\n",
        "  # Feature matrix and labels array for the current subject\n",
        "  currFeats = []\n",
        "  currLabels = []\n",
        "  while (True) :\n",
        "    nextLine = cosFile.readline()\n",
        "    if (not nextLine) : break\n",
        "    currFeats.append([float(nextLine), float(cntFile.readline()), float(hrFile.readline()), float(timeFile.readline())])\n",
        "    currLabels.append(float(labelsFile.readline()))\n",
        "\n",
        "  # Append currFeats, currLabels to features, labels\n",
        "  features.append(np.array(currFeats))\n",
        "  labels.append(np.array(currLabels))\n",
        "\n",
        "  cosFile.close()\n",
        "  cntFile.close()\n",
        "  hrFile.close()\n",
        "  labelsFile.close()\n",
        "  timeFile.close()"
      ],
      "metadata": {
        "id": "unhiw6dad7dz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features. Note that the normalization is being done for each subject\n",
        "# separately\n",
        "\n",
        "for i in range(len(features)) :\n",
        "  features[i] = (features[i] - np.mean(features[i], axis=0)) / np.std(features[i], axis=0)"
      ],
      "metadata": {
        "id": "fGtgNeuZuo4H"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the array binLabels, which is the exact same as labels, but is instead 1\n",
        "# where labels is 5, and 0 otherwise (ie: binLabels is 0 for non-rem and 1 for\n",
        "# rem)\n",
        "\n",
        "binLabelsRem = []\n",
        "for i in range(len(labels)) :\n",
        "  currLabels = np.copy(labels[i])\n",
        "  mask = currLabels == 5\n",
        "  currLabels[mask] = 1\n",
        "  currLabels[np.logical_not(mask)] = 0\n",
        "  binLabelsRem.append(currLabels)"
      ],
      "metadata": {
        "id": "czewLDXZ8yhK"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels for sleep vs wake (wake is positive)\n",
        "\n",
        "binLabelsWake = []\n",
        "for i in range(len(labels)) :\n",
        "  currLabels = np.copy(labels[i])\n",
        "  mask = currLabels == 0\n",
        "  currLabels[mask] = 1\n",
        "  currLabels[np.logical_not(mask)] = 0\n",
        "  binLabelsWake.append(currLabels)"
      ],
      "metadata": {
        "id": "NW2nPa2JQb_T"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels for nrem vs non-nrem (nrem is positive)\n",
        "\n",
        "binLabelsNrem = []\n",
        "for i in range(len(labels)) :\n",
        "  currLabels = np.copy(labels[i])\n",
        "  for j in range(1, 5) :\n",
        "    mask = currLabels == j\n",
        "    currLabels[mask] = 1\n",
        "  mask = currLabels == 1\n",
        "  currLabels[mask] = 1\n",
        "  currLabels[np.logical_not(mask)] = 0\n",
        "  binLabelsNrem.append(currLabels)"
      ],
      "metadata": {
        "id": "LeT9Ur5y1OSI"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the array triLabels, which is the exact same as labels, but is instead 0\n",
        "# where labels is 0, 2 where labels is 5, and 1 otherwise\n",
        "\n",
        "triLabels = []\n",
        "for i in range(len(labels)) :\n",
        "  currLabels = np.copy(labels[i])\n",
        "  for j in range(1, 5) :\n",
        "    mask = currLabels == j\n",
        "    currLabels[mask] = 1\n",
        "  mask = currLabels == 5\n",
        "  currLabels[mask] = 2\n",
        "  triLabels.append(currLabels)"
      ],
      "metadata": {
        "id": "Fii0hvGsl46G"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get number of positive and number of negative data points\n",
        "numPositive = 0\n",
        "numNegative = 0\n",
        "for labels in binLabelsRem :\n",
        "  numPositive += np.sum(labels)\n",
        "  numNegative += len(labels) - np.sum(labels)"
      ],
      "metadata": {
        "id": "8omF5Jsh9H5k"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get number of wake, nrem, rem data points\n",
        "numWakePts, numNremPts, numRemPts = 0, 0, 0\n",
        "for labels in triLabels :\n",
        "  numWakePts += len(labels[labels == 0])\n",
        "  numNremPts += len(labels[labels == 1])\n",
        "  numRemPts += len(labels[labels == 2])\n",
        "# print(f'Wake: {numWakePts}, Nrem: {numNremPts}, Rem: {numRemPts}')"
      ],
      "metadata": {
        "id": "zYAjlUGJsQFH"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do PCA of the features\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(features[0])\n",
        "pts = pca.transform(features[0])\n",
        "mask = binLabelsRem[0] == 1\n",
        "# plt.scatter(pts[mask, 0], pts[mask, 1])\n",
        "# plt.figure()\n",
        "# plt.scatter(pts[np.logical_not(mask), 0], pts[np.logical_not(mask), 1])"
      ],
      "metadata": {
        "id": "mbjVu29X-xWh"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to do leave one out cross validation\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def crossVal(mdl, underSample=False, y=binLabels) :\n",
        "  avgTruePos = 0\n",
        "  avgTrueNeg = 0\n",
        "  avgAcc = 0\n",
        "  avgAuc = 0\n",
        "  numPosTests, numNegTests = 0, 0\n",
        "  for i in range(len(features)) :\n",
        "    testX = features[i]\n",
        "    testY = y[i]\n",
        "    trainX = np.concatenate(features[:i] + features[i + 1:], axis=0)\n",
        "    trainY = np.concatenate(y[:i] + y[i + 1:], axis=0)\n",
        "    # testX = features[i]\n",
        "    # testY = binLabels[i]\n",
        "    # trainX = np.concatenate(features[:i] + features[i + 1:], axis=0)\n",
        "    # trainY = np.concatenate(binLabels[:i] + binLabels[i + 1:], axis=0)\n",
        "    # maskTrain = np.concatenate(binLabelsWake[:i] + binLabelsWake[i + 1:], axis=0)\n",
        "    # trainX = trainX[maskTrain == 0]\n",
        "    # trainY = trainY[maskTrain == 0]\n",
        "    # testX = testX[binLabelsWake[i] == 0]\n",
        "    # testY = testY[binLabelsWake[i] == 0]\n",
        "    mask = testY == 1\n",
        "    # print(i)\n",
        "    numPositive = len(testX[mask])\n",
        "    numNegative = len(testX) - numPositive\n",
        "\n",
        "    mdlCopy = sklearn.base.clone(mdl)\n",
        "\n",
        "    if (underSample) :\n",
        "      trainMask = trainY == 1\n",
        "      trainXPos = trainX[trainMask]\n",
        "      trainXNeg = trainX[np.logical_not(trainMask)]\n",
        "      trainYPos = trainY[trainMask]\n",
        "      trainYNeg = trainY[np.logical_not(trainMask)]\n",
        "      numTrainPos = len(trainXPos)\n",
        "      inds = np.array([i for i in range(len(trainXNeg))])\n",
        "      inds = np.random.choice(inds, numTrainPos)\n",
        "      mdlCopy.fit(trainXPos.tolist() + trainXNeg[inds].tolist(), trainYPos.tolist() + trainYNeg[inds].tolist())\n",
        "    else :\n",
        "      mdlCopy.fit(trainX, trainY)\n",
        "\n",
        "    if (numPositive) :\n",
        "      tpr = mdlCopy.score(testX[mask], testY[mask])\n",
        "      avgTruePos += tpr\n",
        "      numPosTests += 1\n",
        "      # print(f'True positive rate: {tpr}')\n",
        "    if (numNegative) :\n",
        "      tnr = mdlCopy.score(testX[np.logical_not(mask)], testY[np.logical_not(mask)])\n",
        "      avgTrueNeg += tnr\n",
        "      numNegTests += 1\n",
        "      # print(f'True negative rate: {tnr}')\n",
        "    if (numPositive and numNegative) :\n",
        "      auc = roc_auc_score(testY, mdlCopy.predict_proba(testX)[:, 1])\n",
        "      avgAuc += auc\n",
        "      # print(f'AUC: {auc}')\n",
        "    avgAcc += mdlCopy.score(testX, testY)\n",
        "    # print()\n",
        "  print(f'Avg true positive rate: {avgTruePos / numPosTests}')\n",
        "  print(f'Avg true negative rate: {avgTrueNeg / numNegTests}')\n",
        "  print(f'Avg accuracy: {avgAcc / len(features)}')\n",
        "  print(f'Avg auc: {avgAuc / len(features)}')\n",
        "\n",
        "\n",
        "def crossValTern(mdl, underSample=False) :\n",
        "  avgWake, avgNrem, avgRem, avgAcc, avgCohenKappa = 0, 0, 0, 0, 0\n",
        "  numWakeTests, numNremTests, numRemTests = 0, 0, 0\n",
        "  for i in range(len(features)) :\n",
        "    # print(i)\n",
        "    testX = features[i]\n",
        "    testY = triLabels[i]\n",
        "    trainX = np.concatenate(features[:i] + features[i + 1:], axis=0)\n",
        "    trainY = np.concatenate(triLabels[:i] + triLabels[i + 1:], axis=0)\n",
        "\n",
        "    mdlCopy = sklearn.base.clone(mdl)\n",
        "\n",
        "    if (underSample) :\n",
        "      trainXWake = trainX[trainY == 0]\n",
        "      trainXNrem = trainX[trainY == 1]\n",
        "      trainXRem = trainX[trainY == 2]\n",
        "      trainYWake = trainY[trainY == 0]\n",
        "      trainYNrem = trainY[trainY == 1]\n",
        "      trainYRem = trainY[trainY == 2]\n",
        "      numSamples = min(len(trainXWake), len(trainXNrem), len(trainXRem))\n",
        "\n",
        "      inds = np.array([i for i in range(len(trainXWake))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXWake = trainXWake[inds].tolist()\n",
        "      trainYWake = trainYWake[inds].tolist()\n",
        "\n",
        "      inds = np.array([i for i in range(len(trainXNrem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXNrem = trainXNrem[inds].tolist()\n",
        "      trainYNrem = trainYNrem[inds].tolist()\n",
        "\n",
        "      inds = np.array([i for i in range(len(trainXRem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXRem = trainXRem[inds].tolist()\n",
        "      trainYRem = trainYRem[inds].tolist()\n",
        "\n",
        "      mdlCopy.fit(trainXWake + trainXNrem + trainXRem, trainYWake + trainYNrem + trainYRem)\n",
        "    else :\n",
        "      mdlCopy.fit(trainX, trainY)\n",
        "\n",
        "    maskWake = testY == 0\n",
        "    numWake = len(testX[maskWake])\n",
        "    maskNrem = testY == 1\n",
        "    numNrem = len(testX[maskNrem])\n",
        "    maskRem = testY == 2\n",
        "    numRem = len(testX[maskRem])\n",
        "    # print(numWake, numNrem, numRem)\n",
        "\n",
        "    if (numWake) :\n",
        "      wakeScore = mdlCopy.score(testX[maskWake], testY[maskWake])\n",
        "      avgWake += wakeScore\n",
        "      numWakeTests += 1\n",
        "      # print(f'Wake score: {wakeScore}')\n",
        "    if (numNrem) :\n",
        "      nremScore = mdlCopy.score(testX[maskNrem], testY[maskNrem])\n",
        "      avgNrem += nremScore\n",
        "      numNremTests += 1\n",
        "      # print(f'Nrem Score: {nremScore}')\n",
        "    if (numRem) :\n",
        "      remScore = mdlCopy.score(testX[maskRem], testY[maskRem])\n",
        "      avgRem += remScore\n",
        "      numRemTests += 1\n",
        "      # print(f'Rem score: {remScore}')\n",
        "\n",
        "    avgAcc += mdlCopy.score(testX, testY)\n",
        "    avgCohenKappa += cohen_kappa_score(mdlCopy.predict(testX), testY)\n",
        "    # print()\n",
        "  print(f'Avg wake score: {avgWake / numWakeTests}')\n",
        "  print(f'Avg nrem score: {avgNrem / numNremTests}')\n",
        "  print(f'Avg rem score: {avgRem / numRemTests}')\n",
        "  print(f'Avg accuracy: {avgAcc / len(features)}')\n",
        "  print(f'Avg cohen kappa score: {avgCohenKappa / len(features)}')\n",
        "  # return (avgWake / numWakeTests, avgNrem / numNremTests, avgRem / numRemTests, avgAcc / len(features))"
      ],
      "metadata": {
        "id": "FrWjKfJ3fiHl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to, given trained wake, rem, and nrem classifiers, output a score of\n",
        "# the custom model\n",
        "\n",
        "# Function to give posterior probability\n",
        "def posteriorProb(i1, i2, i3, wakePrior, remPrior, nremPrior, y) :\n",
        "  if (i1 == 1 and i2 == 1 and i3 == 1) :\n",
        "    y0 = 0.82 * 0.4 * 0.33 * wakePrior\n",
        "    y1 = 0.19 * 0.4 * 0.67 * nremPrior\n",
        "    y2 = 0.19 * 0.8 * 0.33 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 1 and i2 == 1 and i3 == 0) :\n",
        "    y0 = 0.82 * 0.4 * 0.67 * wakePrior\n",
        "    y1 = 0.19 * 0.4 * 0.33 * nremPrior\n",
        "    y2 = 0.19 * 0.8 * 0.67 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 1 and i2 == 0 and i3 == 1) :\n",
        "    y0 = 0.82 * 0.6 * 0.33 * wakePrior\n",
        "    y1 = 0.19 * 0.6 * 0.67 * nremPrior\n",
        "    y2 = 0.19 * 0.2 * 0.33 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 1 and i2 == 0 and i3 == 0) :\n",
        "    y0 = 0.82 * 0.6 * 0.67 * wakePrior\n",
        "    y1 = 0.19 * 0.6 * 0.33 * nremPrior\n",
        "    y2 = 0.19 * 0.2 * 0.67 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 0 and i2 == 1 and i3 == 1) :\n",
        "    y0 = 0.18 * 0.4 * 0.33 * wakePrior\n",
        "    y1 = 0.81 * 0.4 * 0.67 * nremPrior\n",
        "    y2 = 0.81 * 0.8 * 0.33 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 0 and i2 == 1 and i3 == 0) :\n",
        "    y0 = 0.18 * 0.4 * 0.67 * wakePrior\n",
        "    y1 = 0.81 * 0.4 * 0.33 * nremPrior\n",
        "    y2 = 0.81 * 0.8 * 0.67 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  elif (i1 == 0 and i2 == 0 and i3 == 1) :\n",
        "    y0 = 0.18 * 0.6 * 0.33 * wakePrior\n",
        "    y1 = 0.81 * 0.6 * 0.67 * nremPrior\n",
        "    y2 = 0.81 * 0.2 * 0.33 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "  else :\n",
        "    y0 = 0.18 * 0.6 * 0.67 * wakePrior\n",
        "    y1 = 0.81 * 0.6 * 0.33 * nremPrior\n",
        "    y2 = 0.81 * 0.2 * 0.67 * remPrior\n",
        "    s = y0 + y1 + y2\n",
        "    if (y == 0) : return y0 * wakePrior / s\n",
        "    if (y == 1) : return y1 * nremPrior / s\n",
        "    if (y == 2) : return y2 * remPrior / s\n",
        "\n",
        "\n",
        "def sample(p) :\n",
        "  return np.random.uniform() < p\n",
        "\n",
        "def customScore(wakeClf, remClf, nremClf, testX, testY, wakePrior, remPrior, nremPrior, mlp=None) :\n",
        "  score = 0\n",
        "  # for i in range(len(testX)) :\n",
        "  #   out = wakeClf.predict([testX[i]])[0]\n",
        "  #   if (out == 1) : # Predicted to be awake\n",
        "  #     score += 1 if testY[i] == 0 else 0\n",
        "  #   else :\n",
        "  #     out = remClf.predict([testX[i]])[0]\n",
        "  #     if (out == 0) : # Predicted to be not rem\n",
        "  #       score += 1 if testY[i] == 1 else 0\n",
        "  #     else :\n",
        "  #       score += 1 if testY[i] == 2 else 0\n",
        "\n",
        "  for i in range(len(testX)) :\n",
        "    out = wakeClf.predict([testX[i]])[0]\n",
        "    if (out == 1) : # Predicted to be awake\n",
        "      score += 1 if testY[i] == 0 else 0\n",
        "    else :\n",
        "      outRem = remClf.predict([testX[i]])[0]\n",
        "      outNrem = nremClf.predict([testX[i]])[0]\n",
        "      if ((not outRem) and outNrem) :\n",
        "        pred = 1\n",
        "      elif ((not outRem) and (not outNrem)) :\n",
        "        pred = 2\n",
        "      elif (outRem and outNrem) :\n",
        "        pred = 1\n",
        "      else :\n",
        "        pred = 2\n",
        "      score += 1 if testY[i] == pred else 0\n",
        "      # if (out == 0) : # Predicted to be not rem\n",
        "      #   score += 1 if testY[i] == 1 else 0\n",
        "      # else :\n",
        "      #   score += 1 if testY[i] == 2 else 0\n",
        "\n",
        "\n",
        "  # for i in range(len(testX)) :\n",
        "  #   outWake = wakeClf.predict([testX[i]])[0]\n",
        "  #   outRem = remClf.predict([testX[i]])[0]\n",
        "  #   outNrem = nremClf.predict([testX[i]])[0]\n",
        "  #   posteriorWake = posteriorProb(outWake, outRem, outNrem, wakePrior, remPrior, nremPrior, 0)\n",
        "  #   posteriorRem = posteriorProb(outWake, outRem, outNrem, wakePrior, remPrior, nremPrior, 2)\n",
        "  #   posteriorNrem = posteriorProb(outWake, outRem, outNrem, wakePrior, remPrior, nremPrior, 1)\n",
        "  #   pred = np.argmax(np.array([posteriorWake, posteriorNrem, posteriorRem]))\n",
        "  #   # print([posteriorWake, posteriorNrem, posteriorRem])\n",
        "  #   # print([outWake, outNrem, outRem])\n",
        "  #   score += 1 if pred == testY[i] else 0\n",
        "\n",
        "  # for i in range(len(testX)) :\n",
        "  #   outWake = wakeClf.predict([testX[i]])[0]\n",
        "  #   outRem = remClf.predict([testX[i]])[0]\n",
        "  #   outNrem = nremClf.predict([testX[i]])[0]\n",
        "  #   pred = mlp.predict([[outWake, outNrem, outRem]])[0]\n",
        "  #   score += 1 if pred == testY[i] else 0\n",
        "\n",
        "  return score / len(testX)"
      ],
      "metadata": {
        "id": "BAxhm3ko0m1R"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation for custom model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "  pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "def crossValCustom(wakeClf, remClf, nremClf, underSample=False) :\n",
        "  avgWake, avgNrem, avgRem, avgAcc, avgCohenKappa = 0, 0, 0, 0, 0\n",
        "  numWakeTests, numNremTests, numRemTests = 0, 0, 0\n",
        "  for i in range(len(features)) :\n",
        "    print(i)\n",
        "    testX = features[i]\n",
        "    testY = triLabels[i]\n",
        "    trainX = np.concatenate(features[:i] + features[i + 1:], axis=0)\n",
        "    trainY = np.concatenate(triLabels[:i] + triLabels[i + 1:], axis=0)\n",
        "    trainYWake = np.concatenate(binLabelsWake[:i] + binLabelsWake[i + 1:], axis=0)\n",
        "    trainYRem = np.concatenate(binLabelsRem[:i] + binLabelsRem[i + 1:], axis=0)\n",
        "    trainYNrem = np.concatenate(binLabelsNrem[:i] + binLabelsNrem[i + 1:], axis=0)\n",
        "\n",
        "    # print(len(trainX[trainYNrem == 1]), len(trainX[trainYNrem == 0]))\n",
        "\n",
        "    wakeClfCopy = sklearn.base.clone(wakeClf)\n",
        "    remClfCopy = sklearn.base.clone(remClf)\n",
        "    nremClfCopy = sklearn.base.clone(nremClf)\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(5,), random_state=0, max_iter=50)\n",
        "\n",
        "    if (underSample) :\n",
        "\n",
        "      trainXPosWake = trainX[trainYWake == 1]\n",
        "      trainXNegWake = trainX[trainYWake == 0]\n",
        "      numSamples = min(len(trainXPosWake), len(trainXNegWake))\n",
        "      inds = np.array([i for i in range(len(trainXPosWake))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXPosWake = trainXPosWake[inds].tolist()\n",
        "      inds = np.array([i for i in range(len(trainXNegWake))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXNegWake = trainXNegWake[inds].tolist()\n",
        "      wakeClfCopy.fit(trainXPosWake + trainXNegWake, [1 for i in range(numSamples)] + [0 for i in range(numSamples)])\n",
        "\n",
        "      trainXPosRem = trainX[trainYRem == 1]\n",
        "      trainXNegRem = trainX[trainYRem == 0]\n",
        "      numSamples = min(len(trainXPosRem), len(trainXNegRem))\n",
        "      inds = np.array([i for i in range(len(trainXPosRem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXPosRem = trainXPosRem[inds].tolist()\n",
        "      inds = np.array([i for i in range(len(trainXNegRem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXNegRem = trainXNegRem[inds].tolist()\n",
        "      remClfCopy.fit(trainXPosRem + trainXNegRem, [1 for i in range(numSamples)] + [0 for i in range(numSamples)])\n",
        "\n",
        "      trainXPosNrem = trainX[trainYNrem == 1]\n",
        "      trainXNegNrem = trainX[trainYNrem == 0]\n",
        "      numSamples = min(len(trainXPosNrem), len(trainXNegNrem))\n",
        "      inds = np.array([i for i in range(len(trainXPosNrem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXPosNrem = trainXPosNrem[inds].tolist()\n",
        "      inds = np.array([i for i in range(len(trainXNegNrem))])\n",
        "      inds = np.random.choice(inds, numSamples)\n",
        "      trainXNegNrem = trainXNegNrem[inds].tolist()\n",
        "      nremClfCopy.fit(trainXPosNrem + trainXNegNrem, [1 for i in range(numSamples)] + [0 for i in range(numSamples)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # trainXWake = trainX[trainY == 0]\n",
        "      # trainXNrem = trainX[trainY == 1]\n",
        "      # trainXRem = trainX[trainY == 2]\n",
        "      # trainYWake = trainY[trainY == 0]\n",
        "      # trainYNrem = trainY[trainY == 1]\n",
        "      # trainYRem = trainY[trainY == 2]\n",
        "      # numSamples = min(len(trainXWake), len(trainXNrem), len(trainXRem))\n",
        "\n",
        "      # inds = np.array([i for i in range(len(trainXWake))])\n",
        "      # inds = np.random.choice(inds, numSamples)\n",
        "      # trainXWake = trainXWake[inds].tolist()\n",
        "      # trainYWake = trainYWake[inds].tolist()\n",
        "\n",
        "      # inds = np.array([i for i in range(len(trainXNrem))])\n",
        "      # inds = np.random.choice(inds, numSamples)\n",
        "      # trainXNrem = trainXNrem[inds].tolist()\n",
        "      # trainYNrem = trainYNrem[inds].tolist()\n",
        "\n",
        "      # inds = np.array([i for i in range(len(trainXRem))])\n",
        "      # inds = np.random.choice(inds, numSamples)\n",
        "      # trainXRem = trainXRem[inds].tolist()\n",
        "      # trainYRem = trainYRem[inds].tolist()\n",
        "\n",
        "      # trainXMlp = trainXWake + trainXNrem + trainXRem\n",
        "      # trainMLP = np.array([[0 for j in range(3)] for i in range(len(trainXMlp))])\n",
        "      # trainMLP[:, 0] = wakeClfCopy.predict(trainXMlp)\n",
        "      # trainMLP[:, 1] = nremClfCopy.predict(trainXMlp)\n",
        "      # trainMLP[:, 2] = remClfCopy.predict(trainXMlp)\n",
        "      # mlp.fit(trainMLP, trainYWake + trainYNrem + trainYRem)\n",
        "\n",
        "    else :\n",
        "      wakeClfCopy.fit(trainX, trainYWake)\n",
        "      remClfCopy.fit(trainX, trainYRem)\n",
        "      nremClfCopy.fit(trainX, trainYNrem)\n",
        "\n",
        "      # trainMLP = np.array([[0 for j in range(3)] for i in range(len(trainX))])\n",
        "      # trainMLP[:, 0] = wakeClfCopy.predict(trainX)\n",
        "      # trainMLP[:, 1] = nremClfCopy.predict(trainX)\n",
        "      # trainMLP[:, 2] = remClfCopy.predict(trainX)\n",
        "      # mlp.fit(trainMLP, trainY)\n",
        "\n",
        "    maskWake = testY == 0\n",
        "    numWake = len(testX[maskWake])\n",
        "    maskNrem = testY == 1\n",
        "    numNrem = len(testX[maskNrem])\n",
        "    maskRem = testY == 2\n",
        "    numRem = len(testX[maskRem])\n",
        "    # print(numWake, numNrem, numRem)\n",
        "\n",
        "    wakePrior = len(trainX[trainYWake == 1]) / len(trainX)\n",
        "    remPrior = len(trainX[trainYRem == 1]) / len(trainX)\n",
        "    nremPrior = len(trainX[trainYNrem == 1]) / len(trainX)\n",
        "    wakePrior, nremPrior, remPrior = 0.19, 0.5, 0.32\n",
        "    # print(wakePrior, remPrior, nremPrior)\n",
        "\n",
        "    if (numWake) :\n",
        "      wakeScore = customScore(wakeClfCopy, remClfCopy, nremClfCopy, testX[maskWake], testY[maskWake], wakePrior, remPrior, nremPrior, mlp)\n",
        "      avgWake += wakeScore\n",
        "      numWakeTests += 1\n",
        "      print(f'Wake score: {wakeScore}')\n",
        "    if (numNrem) :\n",
        "      nremScore = customScore(wakeClfCopy, remClfCopy, nremClfCopy, testX[maskNrem], testY[maskNrem], wakePrior, remPrior, nremPrior, mlp)\n",
        "      avgNrem += nremScore\n",
        "      numNremTests += 1\n",
        "      print(f'Nrem Score: {nremScore}')\n",
        "    if (numRem) :\n",
        "      remScore = customScore(wakeClfCopy, remClfCopy, nremClfCopy, testX[maskRem], testY[maskRem], wakePrior, remPrior, nremPrior, mlp)\n",
        "      avgRem += remScore\n",
        "      numRemTests += 1\n",
        "      print(f'Rem score: {remScore}')\n",
        "\n",
        "    avgAcc += customScore(wakeClfCopy, remClfCopy, nremClfCopy, testX, testY, wakePrior, remPrior, nremPrior, mlp)\n",
        "    # avgCohenKappa += cohen_kappa_score(mdlCopy.predict(testX), testY)\n",
        "    print()\n",
        "  print(f'Avg wake score: {avgWake / numWakeTests}')\n",
        "  print(f'Avg nrem score: {avgNrem / numNremTests}')\n",
        "  print(f'Avg rem score: {avgRem / numRemTests}')\n",
        "  print(f'Avg accuracy: {avgAcc / len(features)}')\n",
        "  # print(f'Avg cohen kappa score: {avgCohenKappa / len(features)}')\n",
        "  # return (avgWake / numWakeTests, avgNrem / numNremTests, avgRem / numRemTests, avgAcc / len(features))"
      ],
      "metadata": {
        "id": "AO-d0exIxedP"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Binary logistic regression\n",
        "# class_weight = {0: 1, 1: 4}\n",
        "# logisticRegressionClf = LogisticRegression(random_state=0,\n",
        "#     class_weight=class_weight)\n",
        "\n",
        "# crossVal(logisticRegressionClf)\n",
        "\n",
        "\n",
        "# Ternary logistic regression\n",
        "# class_weight = {0: 6, 1: 1.7, 2: 5}\n",
        "class_weight = {0: 6.566, 1: 1.2, 2: 3.411}\n",
        "logisticRegressionClf = LogisticRegression(random_state=0,\n",
        "    class_weight=class_weight)\n",
        "\n",
        "# crossValTern(logisticRegressionClf)"
      ],
      "metadata": {
        "id": "gZzGOo-M0rvR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree\n",
        "from sklearn import tree\n",
        "\n",
        "# Binary decision tree\n",
        "# decisionTreeClf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, class_weight=class_weight)\n",
        "# crossVal(decisionTreeClf)\n",
        "\n",
        "# Binary decision tree for sleep vs wake\n",
        "decisionTreeClf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "# crossVal(decisionTreeClf, underSample=True, y=binLabelsWake)\n",
        "\n",
        "# Ternary decision tree\n",
        "class_weight = {0: 3.89, 1: 1.87, 2: 3.19}\n",
        "# decisionTreeClf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, class_weight=class_weight)\n",
        "# crossValTern(decisionTreeClf)"
      ],
      "metadata": {
        "id": "cGEDJtYOFrVu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Binary gradient boosting\n",
        "gradBoostingClf = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
        "# crossVal(gradBoostingClf, underSample=True)\n",
        "# print()\n",
        "# Gradient boosting for sleep vs wake\n",
        "gradBoostingClf = GradientBoostingClassifier(n_estimators=20, random_state=0)\n",
        "# crossVal(gradBoostingClf, underSample=True, y=binLabelsWake)\n",
        "# print()\n",
        "\n",
        "# Gradient boosting for nrem vs other\n",
        "gradBoostingClf = GradientBoostingClassifier(n_estimators=20, random_state=0)\n",
        "# crossVal(gradBoostingClf, underSample=True, y=binLabelsNrem)\n",
        "\n",
        "# wakeClf = GradientBoostingClassifier(n_estimators=20, random_state=0)\n",
        "# remClf = GradientBoostingClassifier(n_estimators=20, random_state=0)\n",
        "# nremClf = GradientBoostingClassifier(n_estimators=20, random_state=0)\n",
        "# crossValCustom(wakeClf, remClf, nremClf, underSample=True)\n",
        "\n",
        "\n",
        "# Ternary gradient boosting\n",
        "gradBoostingClf = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
        "# crossValTern(gradBoostingClf, underSample=True)"
      ],
      "metadata": {
        "id": "4WmXHbUPFsLX"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "\n",
        "# Ternary mlp classification\n",
        "mlpClf = MLPClassifier(hidden_layer_sizes=(5,10,), random_state=0, max_iter=50)\n",
        "# crossValTern(mlpClf, underSample=True)\n",
        "# crossVal(mlpClf, underSample=True, y=binLabelsWake)"
      ],
      "metadata": {
        "id": "Hd4hUjHMXHRe"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble algorithms\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Decision tree bagging classifier\n",
        "decisionTreeBagging = BaggingClassifier(tree.DecisionTreeClassifier(criterion='entropy', max_depth=3),\n",
        "    max_samples=0.5, max_features=0.5)\n",
        "\n",
        "# crossValTern(decisionTreeBagging, underSample=True)\n",
        "\n",
        "# Logistic regression bagging classifier\n",
        "logRegBagging = BaggingClassifier(LogisticRegression(random_state=0),\n",
        "    max_samples=0.5, max_features=0.5)\n",
        "\n",
        "# crossValTern(logRegBagging, underSample=True)\n",
        "\n",
        "# Random forest\n",
        "randomForestClf = RandomForestClassifier(n_estimators=10, criterion='entropy')\n",
        "# crossValTern(randomForestClf, underSample=True)\n",
        "\n",
        "# Random forest for sleep vs wake\n",
        "# randomForestClf = RandomForestClassifier(n_estimators=10, criterion='entropy')\n",
        "# crossVal(randomForestClf, underSample=True, y=binLabelsWake)"
      ],
      "metadata": {
        "id": "LJBBLxFY35yc"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class Encoder(nn.Module) :\n",
        "  def __init__(self, latentDims, hiddenDims) :\n",
        "    super(Encoder, self).__init__()\n",
        "    self.linear1 = nn.Linear(4, hiddenDims)\n",
        "    self.linear2 = nn.Linear(hiddenDims, latentDims)\n",
        "  def forward(self, x) :\n",
        "    # x = torch.flatten(x, start_dim=1)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    return self.linear2(x)\n",
        "\n",
        "class Decoder(nn.Module) :\n",
        "  def __init__(self, latentDims, hiddenDims) :\n",
        "    super(Decoder, self).__init__()\n",
        "    self.linear1 = nn.Linear(latentDims, hiddenDims)\n",
        "    self.linear2 = nn.Linear(hiddenDims, 4)\n",
        "  def forward(self, x) :\n",
        "    x = F.relu(self.linear1(x))\n",
        "    # x = torch.sigmoid(self.linear2(x))\n",
        "    x = self.linear2(x)\n",
        "    return x\n",
        "\n",
        "class Autoencoder(nn.Module) :\n",
        "  def __init__(self, latentDims, hiddenDims) :\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = Encoder(latentDims, hiddenDims)\n",
        "    self.decoder = Decoder(latentDims, hiddenDims)\n",
        "  def forward(self, x) :\n",
        "    x = self.encoder(x)\n",
        "    return self.decoder(x)\n",
        "\n",
        "def train(autoencoder, data, epochs=40) :\n",
        "  autoencoder = autoencoder.to(device)\n",
        "  optim = torch.optim.Adam(autoencoder.parameters())\n",
        "  for epoch in range(epochs) :\n",
        "    epochLoss = 0\n",
        "    for x in data :\n",
        "      optim.zero_grad()\n",
        "      x = x.to(device)\n",
        "      x_hat = autoencoder(x)\n",
        "      loss = ((x - x_hat) ** 2).sum()\n",
        "      epochLoss += loss\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "    print(f'Epoch #{epoch}: {epochLoss}')\n",
        "  return autoencoder\n",
        "\n",
        "def plotLatent(autoencoder, dataX, dataY, numBatches=2) :\n",
        "  for i in range(len(dataX)) :\n",
        "    x = dataX[i]\n",
        "    y = dataY[i]\n",
        "    z = autoencoder.encoder(x.to(device))\n",
        "    z = z.cpu().detach().numpy()\n",
        "    plt.scatter(z[:, 0], z[:, 1], c=y)\n",
        "    if (i >= numBatches) :\n",
        "      plt.colorbar()\n",
        "      break\n",
        "\n",
        "autoencoder = Autoencoder(2, 1000)\n",
        "data = features.copy()\n",
        "for i in range(len(data)) :\n",
        "  data[i] = torch.tensor(data[i]).float()\n",
        "# autoencoder = train(autoencoder, data)"
      ],
      "metadata": {
        "id": "WGhyqpRqFSfz"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataX = features.copy()\n",
        "for i in range(len(features)) :\n",
        "  dataX[i] = torch.tensor(features[i]).float()\n",
        "# plotLatent(autoencoder, dataX, binLabelsRem)"
      ],
      "metadata": {
        "id": "xX7hV6O9TDzP"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEjlkK-xs1ji"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}